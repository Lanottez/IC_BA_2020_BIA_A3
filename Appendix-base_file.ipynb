{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to build you code based on this one, so it will be easier for us to intergate all the codes into one file\n",
    "# Create a function for each plot that you want to call\n",
    "# Replace the screenshot in final report to the function you want to call "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math \n",
    "from datetime import datetime\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt  \n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Club</th>\n",
       "      <th>Join Date</th>\n",
       "      <th>Affluence</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Subscription Type</th>\n",
       "      <th>End Date</th>\n",
       "      <th>CustomerID</th>\n",
       "      <th>BirthYear</th>\n",
       "      <th>Join_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Enfield</td>\n",
       "      <td>2011-12-01</td>\n",
       "      <td>C1</td>\n",
       "      <td>Male</td>\n",
       "      <td>Standard</td>\n",
       "      <td>2011-12-01</td>\n",
       "      <td>1</td>\n",
       "      <td>1992</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Islington</td>\n",
       "      <td>2018-03-01</td>\n",
       "      <td>B</td>\n",
       "      <td>Female</td>\n",
       "      <td>Standard</td>\n",
       "      <td>2018-10-01</td>\n",
       "      <td>3</td>\n",
       "      <td>1985</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hounslow</td>\n",
       "      <td>2015-10-01</td>\n",
       "      <td>C1</td>\n",
       "      <td>Female</td>\n",
       "      <td>Standard</td>\n",
       "      <td>2015-12-01</td>\n",
       "      <td>4</td>\n",
       "      <td>1972</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Barnet</td>\n",
       "      <td>2015-05-01</td>\n",
       "      <td>C2</td>\n",
       "      <td>Male</td>\n",
       "      <td>Standard</td>\n",
       "      <td>2015-12-01</td>\n",
       "      <td>5</td>\n",
       "      <td>1982</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Harrow</td>\n",
       "      <td>2017-03-01</td>\n",
       "      <td>C1</td>\n",
       "      <td>Male</td>\n",
       "      <td>Standard</td>\n",
       "      <td>2017-05-01</td>\n",
       "      <td>6</td>\n",
       "      <td>1982</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>850027</th>\n",
       "      <td>Haringey</td>\n",
       "      <td>2016-11-01</td>\n",
       "      <td>C1</td>\n",
       "      <td>Male</td>\n",
       "      <td>Flexible</td>\n",
       "      <td>2017-02-01</td>\n",
       "      <td>850028</td>\n",
       "      <td>1984</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>850029</th>\n",
       "      <td>Tower Hamlets</td>\n",
       "      <td>2013-10-01</td>\n",
       "      <td>B</td>\n",
       "      <td>Male</td>\n",
       "      <td>Standard</td>\n",
       "      <td>2014-02-01</td>\n",
       "      <td>850030</td>\n",
       "      <td>1987</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>850030</th>\n",
       "      <td>Redbridge</td>\n",
       "      <td>2018-05-01</td>\n",
       "      <td>C1</td>\n",
       "      <td>Female</td>\n",
       "      <td>Standard</td>\n",
       "      <td>2018-09-01</td>\n",
       "      <td>850031</td>\n",
       "      <td>1985</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>850031</th>\n",
       "      <td>Camden</td>\n",
       "      <td>2017-07-01</td>\n",
       "      <td>B</td>\n",
       "      <td>Female</td>\n",
       "      <td>Standard</td>\n",
       "      <td>2017-09-01</td>\n",
       "      <td>850032</td>\n",
       "      <td>1978</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>850032</th>\n",
       "      <td>Greenwich</td>\n",
       "      <td>2015-10-01</td>\n",
       "      <td>C1</td>\n",
       "      <td>Male</td>\n",
       "      <td>Standard</td>\n",
       "      <td>2015-12-01</td>\n",
       "      <td>850033</td>\n",
       "      <td>1989</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>797656 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Club  Join Date Affluence  Gender Subscription Type  \\\n",
       "0             Enfield 2011-12-01        C1    Male          Standard   \n",
       "2           Islington 2018-03-01         B  Female          Standard   \n",
       "3            Hounslow 2015-10-01        C1  Female          Standard   \n",
       "4              Barnet 2015-05-01        C2    Male          Standard   \n",
       "5              Harrow 2017-03-01        C1    Male          Standard   \n",
       "...               ...        ...       ...     ...               ...   \n",
       "850027       Haringey 2016-11-01        C1    Male          Flexible   \n",
       "850029  Tower Hamlets 2013-10-01         B    Male          Standard   \n",
       "850030      Redbridge 2018-05-01        C1  Female          Standard   \n",
       "850031         Camden 2017-07-01         B  Female          Standard   \n",
       "850032      Greenwich 2015-10-01        C1    Male          Standard   \n",
       "\n",
       "         End Date  CustomerID  BirthYear  Join_year  \n",
       "0      2011-12-01           1       1992       2011  \n",
       "2      2018-10-01           3       1985       2018  \n",
       "3      2015-12-01           4       1972       2015  \n",
       "4      2015-12-01           5       1982       2015  \n",
       "5      2017-05-01           6       1982       2017  \n",
       "...           ...         ...        ...        ...  \n",
       "850027 2017-02-01      850028       1984       2016  \n",
       "850029 2014-02-01      850030       1987       2013  \n",
       "850030 2018-09-01      850031       1985       2018  \n",
       "850031 2017-09-01      850032       1978       2017  \n",
       "850032 2015-12-01      850033       1989       2015  \n",
       "\n",
       "[797656 rows x 9 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import data\n",
    "# This cell should applies to the code of all of us\n",
    "data_path = \"./data/\"\n",
    "subscriptions = pd.read_csv(data_path + 'subscriptionsdataFINAL.csv') \n",
    "visitation_part1 = pd.read_csv(data_path + 'visitationdataPART1.csv') \n",
    "visitation_part2 = pd.read_csv(data_path + 'visitationdataPART2.csv') #convert the join and end date to_date\n",
    "subscriptions['Join Date'] =  pd.to_datetime(subscriptions['Join Date'].str.upper(), format='%b-%y', yearfirst=False)\n",
    "subscriptions['Join_year'] = pd.DatetimeIndex(subscriptions['Join Date']).year\n",
    "subscriptions['End Date'] =  pd.to_datetime(subscriptions['End Date'].str.upper(), format='%b-%y', yearfirst=False)\n",
    "subscriptions.dropna() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the seperate dataset to avoid any variable name conflict \n",
    "subscriptions_Qian =  subscriptions.copy()\n",
    "visitation_part1_Qian = visitation_part1.copy() \n",
    "visitation_part2_Qian = visitation_part2.copy()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Processing - Qian\n",
    "df = subscriptions_Qian.copy()\n",
    "date_min = min (df['Join Date'].min(),df['End Date'].min() )\n",
    "date_max = max (df['Join Date'].max(),df['End Date'].max() )\n",
    "df['Duration'] = np.where(df['End Date'].isna(), \n",
    "                                     (date_max - df['Join Date']), \n",
    "                                     (df['End Date'] - df['Join Date']) )\n",
    "df['Duration'] = (df['Duration'] /  np.timedelta64(1, 'M') ).apply(math.floor)\n",
    "df.loc[(df.Duration <= 2),'Duration']=2\n",
    "def extend_early_standard_to_three_months(join_date,duration):\n",
    "    return join_date + pd.DateOffset(months=duration)\n",
    "df['End Date']=df.apply(lambda row: extend_early_standard_to_three_months(row['Join Date'], row['Duration']),axis=1)\n",
    "df=df.drop(columns=['Duration'])\n",
    "\n",
    "numbers_club = pd.DataFrame(df.groupby('Join_year')['Club'].nunique())\n",
    "numbers_club['Growth']=numbers_club['Club'].pct_change()\n",
    "member_joined_data = subscriptions.groupby(['Join Date','Subscription Type']).size().reset_index(name='Number_of_member_joined')\n",
    "member_joined_data = member_joined_data.rename(columns={'Join Date': \"Date\"})\n",
    "member_left_data = subscriptions.groupby(['End Date','Subscription Type']).size().reset_index(name='Number_of_member_left')\n",
    "member_left_data=member_left_data.rename(columns={'End Date': \"Date\"})\n",
    "member_left_data['Date']=member_left_data['Date'] + pd.DateOffset(months=1)\n",
    "member_data = pd.merge(member_joined_data,member_left_data,on = ['Subscription Type','Date'],how='outer').sort_index().replace({np.nan:0})\n",
    "member_data['net_member'] = member_data['Number_of_member_joined'] - member_data['Number_of_member_left'] \n",
    "member_data = member_data.drop(columns = ['Number_of_member_joined', 'Number_of_member_left'])\n",
    "Cumulative_Members = pd.DataFrame(member_data.groupby(['Date']).sum('net_member').unstack(fill_value=0))\n",
    "Cumulative_Members = Cumulative_Members.rename(columns={0: \"Cumulative_members\"})\n",
    "Cumulative_Members = Cumulative_Members.cumsum().reset_index()\n",
    "Cumulative_Members_yearly = Cumulative_Members.copy()\n",
    "Cumulative_Members_yearly['year'] = pd.DatetimeIndex(Cumulative_Members_yearly['Date']).year\n",
    "Cumulative_Members_yearly=Cumulative_Members_yearly.groupby(['year']).sum()\n",
    "Cumulative_Members_yearly=Cumulative_Members_yearly.drop([2019])\n",
    "Cumulative_Members_yearly['Cumulative_members_Grwoth']=Cumulative_Members_yearly['Cumulative_members'].pct_change()\n",
    "Cumulative_Members_seperating = pd.DataFrame(member_data.groupby(['Date','Subscription Type']).sum('net_member').unstack(fill_value=0))\n",
    "Cumulative_Members_seperating = Cumulative_Members_seperating.rename(columns={0: \"Cumulative_members\"})\n",
    "Cumulative_Members_seperating = Cumulative_Members_seperating.cumsum().reset_index()\n",
    "x = Cumulative_Members_seperating['net_member']\n",
    "y = pd.DataFrame({'Date':Cumulative_Members_seperating['Date']})\n",
    "y['Flexible']=x['Flexible']\n",
    "y['Standard']=x['Standard']\n",
    "Cumulative_Members_seperating=y\n",
    "def calculate_revenue_flexible(Date,net_member):\n",
    "    date_while_price_changed = pd.Timestamp('2016-01-01') \n",
    "    if Date < date_while_price_changed:\n",
    "        return net_member * 25.99\n",
    "    elif Date >= date_while_price_changed:\n",
    "        return net_member * 30.99\n",
    "def calculate_revenue_standard(Date,net_member):\n",
    "    date_while_price_changed = pd.Timestamp('2016-01-01') \n",
    "    if Date < date_while_price_changed:\n",
    "        return net_member * 20.99\n",
    "    elif Date >= date_while_price_changed:\n",
    "        return net_member * 26.99 \n",
    "Cumulative_Members_seperating_revenue = Cumulative_Members_seperating.copy()\n",
    "Cumulative_Members_seperating_revenue['Flexible_revenue']=Cumulative_Members_seperating_revenue.apply(lambda row: calculate_revenue_flexible(row['Date'], row['Flexible']),axis=1)\n",
    "Cumulative_Members_seperating_revenue['Standard_revenue']=Cumulative_Members_seperating_revenue.apply(lambda row: calculate_revenue_standard(row['Date'], row['Standard']),axis=1)\n",
    "Cumulative_Members_seperating_revenue['Total_revenue']=Cumulative_Members_seperating_revenue['Flexible_revenue'] + Cumulative_Members_seperating_revenue['Standard_revenue']\n",
    "Cumulative_Members_seperating_revenue_yearly = Cumulative_Members_seperating_revenue.copy()\n",
    "Cumulative_Members_seperating_revenue_yearly['year'] = pd.DatetimeIndex(Cumulative_Members_seperating_revenue_yearly['Date']).year\n",
    "Cumulative_Members_seperating_revenue_yearly=Cumulative_Members_seperating_revenue_yearly.groupby(['year']).sum()\n",
    "Cumulative_Members_seperating_revenue_yearly=Cumulative_Members_seperating_revenue_yearly.drop([2019])\n",
    "Cumulative_Members_seperating_revenue_yearly['Revenue_grwoth']=Cumulative_Members_seperating_revenue_yearly['Total_revenue'].pct_change()\n",
    "subscriptions_2 = subscriptions_Qian.copy()\n",
    "date_min = min (subscriptions_2['Join Date'].min(),subscriptions_2['End Date'].min() )\n",
    "date_max = max (subscriptions_2['Join Date'].max(),subscriptions_2['End Date'].max() )\n",
    "dates = pd.date_range(date_min, date_max, freq = 'MS')\n",
    "subscriptions_2['Duration'] = np.where(subscriptions_2['End Date'].isna(), \n",
    "                                     (date_max - subscriptions_2['Join Date']), \n",
    "                                     (subscriptions_2['End Date'] - subscriptions_2['Join Date']) )\n",
    "subscriptions_2['Duration'] = (subscriptions_2['Duration'] /  np.timedelta64(1, 'M') ).apply(math.floor)\n",
    "subscriptions_3= subscriptions_2.copy()\n",
    "visitation_part1_peakvisit = visitation_part1.groupby(['CustomerID', 'peakvisits']).size().unstack(fill_value=0)\n",
    "visitation_part2_peakvisit = visitation_part2.groupby(['CustomerID', 'peakvisits']).size().unstack(fill_value=0)\n",
    "visitation_peakvisit = pd.merge(visitation_part1_peakvisit,visitation_part2_peakvisit,on='CustomerID',how='outer').sort_index().replace({np.nan:0})\n",
    "visitation_peakvisit['False'] = visitation_peakvisit['False_x'] + visitation_peakvisit['False_y']\n",
    "visitation_peakvisit['True'] = visitation_peakvisit['True_x'] + visitation_peakvisit['True_y']\n",
    "visitation_peakvisit=visitation_peakvisit.drop(columns=['False_x','True_x','False_y','True_y'])\n",
    "visitation_peakvisit['Peak_proportion'] = visitation_peakvisit['True']/(visitation_peakvisit['True'] + visitation_peakvisit['False'])\n",
    "def classify_peak(Peak_proportion):\n",
    "    if Peak_proportion < 0.35:\n",
    "        return 'Off_Peak_Customer'\n",
    "    elif 0.25 <= Peak_proportion < 0.65:\n",
    "        return 'Average'\n",
    "    else:\n",
    "        return 'Peak_Customer'\n",
    "visitation_peakvisit['Peak_categogy'] = visitation_peakvisit['Peak_proportion'].apply(lambda x : classify_peak(x))\n",
    "\n",
    "def plot_KNN_model(size_dataset,k_value):\n",
    "    subscriptions_3= subscriptions_2.copy()\n",
    "    subscriptions_3 = pd.merge(subscriptions_3,visitation_peakvisit['Peak_categogy'],on='CustomerID',how='outer')\n",
    "    subscriptions_3 = subscriptions_3[:size_dataset]\n",
    "    subscriptions_4=subscriptions_3.copy().drop(columns=['End Date','CustomerID'])\n",
    "    def normalises_string(data,data_list):\n",
    "        index = data_list.index(data)\n",
    "        return index\n",
    "    for column in subscriptions_4.columns:\n",
    "        if column != 'Duration':\n",
    "            subscriptions_4[column] = subscriptions_4.apply(lambda row: normalises_string(row[column], list(subscriptions_4[column].unique())),axis=1)\n",
    "    if size_dataset == 800:\n",
    "        training_data, validation_data, test_data = subscriptions_4[:400], subscriptions_4[400:600], subscriptions_4[600:] \n",
    "    else: #data_set = 4000\n",
    "        training_data, validation_data, test_data = subscriptions_4[:2000], subscriptions_4[2000:3000], subscriptions_4[3000:] \n",
    "    def normalises_the_data_z_score(input_data):\n",
    "        data_normalised = preprocessing.scale(input_data)\n",
    "        data_normalised = pd.DataFrame(data=data_normalised,columns = list(input_data.columns))\n",
    "        data_normalised['Duration'] = input_data['Duration']\n",
    "        return data_normalised\n",
    "    training_data_normalised = normalises_the_data_z_score(training_data)\n",
    "    validation_data_normalised = normalises_the_data_z_score(validation_data)\n",
    "    test_data_normalised = normalises_the_data_z_score(test_data)\n",
    "    training_data_normalised_x = training_data_normalised.copy().drop(columns=['Duration']).values\n",
    "    training_data_normalised_y = training_data['Duration']\n",
    "\n",
    "    validation_data_normalised_x = validation_data_normalised.copy().drop(columns=['Duration']).values\n",
    "    validation_data_normalised_y = validation_data['Duration']\n",
    "    scores_list = []\n",
    "    for k in range(1,k_value):\n",
    "       classifier = KNeighborsClassifier(n_neighbors=k)\n",
    "       classifier.fit(training_data_normalised_x, training_data_normalised_y)\n",
    "       validation_data_normalised_y_predicted = classifier.predict(validation_data_normalised_x)\n",
    "       scores_list.append(1-metrics.accuracy_score(validation_data_normalised_y,validation_data_normalised_y_predicted,normalize=True))\n",
    "    scores_list_df = pd.DataFrame(data=scores_list).rename(columns={0: \"Classificaion error(validation data)\"})\n",
    "    scores_list_df['k-value'] = list(range(1,k_value))\n",
    "    scores_list = []\n",
    "    # The part below is to use the trainning data to predict the training data.\n",
    "    for k in range(1,k_value):\n",
    "       classifier = KNeighborsClassifier(n_neighbors=k)\n",
    "       classifier.fit(training_data_normalised_x, training_data_normalised_y)\n",
    "       training_data_normalised_y_predicted = classifier.predict(training_data_normalised_x)\n",
    "       scores_list.append(1-metrics.accuracy_score(training_data_normalised_y,training_data_normalised_y_predicted,normalize=True))\n",
    "    scores_list_df['Classificaion error(training data)'] = scores_list\n",
    "    plt.plot(scores_list_df['k-value'], scores_list_df['Classificaion error(validation data)'], label = \"Validation data\")\n",
    "    plt.gca().invert_xaxis()\n",
    "    if size_dataset==800:\n",
    "        plt.title('Classification error, 800 rows, k=1-100')\n",
    "    else:\n",
    "        plt.title('Classification error, 4000 rows, k=1-200')\n",
    "    plt.ylabel('%')\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot graph - Qian\n",
    "def plot_growth_of_new_members():\n",
    "    Year = Cumulative_Members_yearly.index.values\n",
    "    Cumulative_members_Grwoth = Cumulative_Members_yearly['Cumulative_members_Grwoth']\n",
    "    plt.plot(Year,Cumulative_members_Grwoth)\n",
    "    plt.ylabel('%')\n",
    "    plt.title('Growth of New Members')\n",
    "def plot_cumulative_active_members():\n",
    "    Date = Cumulative_Members.Date\n",
    "    Cumulative_members = Cumulative_Members.Cumulative_members\n",
    "    plt.plot(Date[:-1],Cumulative_members[:-1])\n",
    "    plt.title('Cumulative Active Members')\n",
    "    plt.axvline(x='2016-01-01')\n",
    "def plot_monthly_revenue():\n",
    "    Date = Cumulative_Members_seperating_revenue['Date']\n",
    "    Total = Cumulative_Members_seperating_revenue['Total_revenue']\n",
    "    plt.plot(Date[:-1],Total[:-1],label = 'Total')\n",
    "    plt.axvline(x='2016-01-01')\n",
    "    plt.ylabel('Pound')\n",
    "    plt.title('Monthly Revenue')\n",
    "def plot_growth_yearly_revenue():\n",
    "    Date = Cumulative_Members_seperating_revenue_yearly.index.values\n",
    "    Revenue_grwoth = Cumulative_Members_seperating_revenue_yearly['Revenue_grwoth']\n",
    "    plt.plot(Date,Revenue_grwoth)\n",
    "    plt.ylabel('%')\n",
    "    plt.title('Yearly Revenue Growth')\n",
    "def plot_bar_yearly_revenue():\n",
    "    r =  np.arange(2009,2019)\n",
    "    Total_revenue = Cumulative_Members_seperating_revenue_yearly['Total_revenue']\n",
    "    plt.ylabel('Pound')\n",
    "    plt.bar(r,Total_revenue)\n",
    "    plt.title('Yearly Revenue')\n",
    "def plot_number_of_club(): \n",
    "    plt.bar(numbers_club.index.values, numbers_club['Club'])\n",
    "    plt.ylabel('Number of Clubs')\n",
    "    plt.title('Number of clubs')\n",
    "def plot_KNN_model_800():\n",
    "    plot_KNN_model(800,101)\n",
    "def plot_KNN_model_4000():\n",
    "    plot_KNN_model(4000,201)\n",
    "def plot_active_member_bar_line():\n",
    "    Cumulative_Members_noseperating_revenue_yearly = Cumulative_Members_seperating_revenue_yearly.copy()\n",
    "    Cumulative_Members_noseperating_revenue_yearly['TotalMember'] = Cumulative_Members_seperating_revenue_yearly['Flexible'] + Cumulative_Members_seperating_revenue_yearly['Standard']\n",
    "    Cumulative_Members_noseperating_revenue_yearly['MemberGrowth'] = Cumulative_Members_noseperating_revenue_yearly['TotalMember'].pct_change()\n",
    "    r =  np.arange(2009,2019)\n",
    "    TotalMember = Cumulative_Members_noseperating_revenue_yearly['TotalMember']\n",
    "    MemberGrowth = Cumulative_Members_noseperating_revenue_yearly['MemberGrowth']\n",
    "    ax=Cumulative_Members_noseperating_revenue_yearly['TotalMember'].plot(kind='bar')\n",
    "    ax2 = ax.twinx()\n",
    "#     Cumulative_Members_noseperating_revenue_yearly['MemberGrowth'].plot(kind='line')\n",
    "    ax2.plot(Cumulative_Members_noseperating_revenue_yearly[['MemberGrowth']].values)\n",
    "    plt.title('Cumulative Active Member and Growth')\n",
    "def plot_yearly_revenue_bar_line():  \n",
    "    Cumulative_Members_noseperating_revenue_yearly = Cumulative_Members_seperating_revenue_yearly.copy()\n",
    "    Cumulative_Members_noseperating_revenue_yearly['TotalMember'] = Cumulative_Members_seperating_revenue_yearly['Flexible'] + Cumulative_Members_seperating_revenue_yearly['Standard']\n",
    "    Cumulative_Members_noseperating_revenue_yearly['MemberGrowth'] = Cumulative_Members_noseperating_revenue_yearly['TotalMember'].pct_change()\n",
    "    r =  np.arange(2009,2019)\n",
    "    Yearly_revenue = Cumulative_Members_seperating_revenue_yearly['Total_revenue']\n",
    "    Revenue_grwoth = Cumulative_Members_seperating_revenue_yearly['Revenue_grwoth']\n",
    "    ax=Cumulative_Members_noseperating_revenue_yearly['Total_revenue'].plot(kind='bar')\n",
    "    ax2 = ax.twinx()\n",
    "    # Cumulative_Members_noseperating_revenue_yearly['Revenue_grwoth'].plot(kind='line')\n",
    "    ax2.plot(Cumulative_Members_noseperating_revenue_yearly[['Revenue_grwoth']].values)\n",
    "    plt.title('Yearly Revenure and Growth')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Flexible</th>\n",
       "      <th>Standard</th>\n",
       "      <th>Flexible_revenue</th>\n",
       "      <th>Standard_revenue</th>\n",
       "      <th>Total_revenue</th>\n",
       "      <th>Revenue_grwoth</th>\n",
       "      <th>TotalMember</th>\n",
       "      <th>MemberGrowth</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2009</th>\n",
       "      <td>4642.0</td>\n",
       "      <td>22511.0</td>\n",
       "      <td>120645.58</td>\n",
       "      <td>472505.89</td>\n",
       "      <td>593151.47</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27153.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010</th>\n",
       "      <td>15118.0</td>\n",
       "      <td>88947.0</td>\n",
       "      <td>392916.82</td>\n",
       "      <td>1866997.53</td>\n",
       "      <td>2259914.35</td>\n",
       "      <td>2.810012</td>\n",
       "      <td>104065.0</td>\n",
       "      <td>2.832542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011</th>\n",
       "      <td>29857.0</td>\n",
       "      <td>178681.0</td>\n",
       "      <td>775983.43</td>\n",
       "      <td>3750514.19</td>\n",
       "      <td>4526497.62</td>\n",
       "      <td>1.002951</td>\n",
       "      <td>208538.0</td>\n",
       "      <td>1.003921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012</th>\n",
       "      <td>41542.0</td>\n",
       "      <td>261364.0</td>\n",
       "      <td>1079676.58</td>\n",
       "      <td>5486030.36</td>\n",
       "      <td>6565706.94</td>\n",
       "      <td>0.450505</td>\n",
       "      <td>302906.0</td>\n",
       "      <td>0.452522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013</th>\n",
       "      <td>53838.0</td>\n",
       "      <td>337201.0</td>\n",
       "      <td>1399249.62</td>\n",
       "      <td>7077848.99</td>\n",
       "      <td>8477098.61</td>\n",
       "      <td>0.291117</td>\n",
       "      <td>391039.0</td>\n",
       "      <td>0.290958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014</th>\n",
       "      <td>62895.0</td>\n",
       "      <td>397703.0</td>\n",
       "      <td>1634641.05</td>\n",
       "      <td>8347785.97</td>\n",
       "      <td>9982427.02</td>\n",
       "      <td>0.177576</td>\n",
       "      <td>460598.0</td>\n",
       "      <td>0.177883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015</th>\n",
       "      <td>76120.0</td>\n",
       "      <td>478627.0</td>\n",
       "      <td>1978358.80</td>\n",
       "      <td>10046380.73</td>\n",
       "      <td>12024739.53</td>\n",
       "      <td>0.204591</td>\n",
       "      <td>554747.0</td>\n",
       "      <td>0.204406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016</th>\n",
       "      <td>86452.0</td>\n",
       "      <td>532411.0</td>\n",
       "      <td>2679147.48</td>\n",
       "      <td>14369772.89</td>\n",
       "      <td>17048920.37</td>\n",
       "      <td>0.417820</td>\n",
       "      <td>618863.0</td>\n",
       "      <td>0.115577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017</th>\n",
       "      <td>100811.0</td>\n",
       "      <td>647245.0</td>\n",
       "      <td>3124132.89</td>\n",
       "      <td>17469142.55</td>\n",
       "      <td>20593275.44</td>\n",
       "      <td>0.207893</td>\n",
       "      <td>748056.0</td>\n",
       "      <td>0.208759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>104905.0</td>\n",
       "      <td>680590.0</td>\n",
       "      <td>3251005.95</td>\n",
       "      <td>18369124.10</td>\n",
       "      <td>21620130.05</td>\n",
       "      <td>0.049864</td>\n",
       "      <td>785495.0</td>\n",
       "      <td>0.050048</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Flexible  Standard  Flexible_revenue  Standard_revenue  Total_revenue  \\\n",
       "year                                                                          \n",
       "2009    4642.0   22511.0         120645.58         472505.89      593151.47   \n",
       "2010   15118.0   88947.0         392916.82        1866997.53     2259914.35   \n",
       "2011   29857.0  178681.0         775983.43        3750514.19     4526497.62   \n",
       "2012   41542.0  261364.0        1079676.58        5486030.36     6565706.94   \n",
       "2013   53838.0  337201.0        1399249.62        7077848.99     8477098.61   \n",
       "2014   62895.0  397703.0        1634641.05        8347785.97     9982427.02   \n",
       "2015   76120.0  478627.0        1978358.80       10046380.73    12024739.53   \n",
       "2016   86452.0  532411.0        2679147.48       14369772.89    17048920.37   \n",
       "2017  100811.0  647245.0        3124132.89       17469142.55    20593275.44   \n",
       "2018  104905.0  680590.0        3251005.95       18369124.10    21620130.05   \n",
       "\n",
       "      Revenue_grwoth  TotalMember  MemberGrowth  \n",
       "year                                             \n",
       "2009             NaN      27153.0           NaN  \n",
       "2010        2.810012     104065.0      2.832542  \n",
       "2011        1.002951     208538.0      1.003921  \n",
       "2012        0.450505     302906.0      0.452522  \n",
       "2013        0.291117     391039.0      0.290958  \n",
       "2014        0.177576     460598.0      0.177883  \n",
       "2015        0.204591     554747.0      0.204406  \n",
       "2016        0.417820     618863.0      0.115577  \n",
       "2017        0.207893     748056.0      0.208759  \n",
       "2018        0.049864     785495.0      0.050048  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Cumulative_Members_noseperating_revenue_yearly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numbers_club.index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
